# QCM Generator Pro - Environment Variables Template
# Copy this file to .env and fill in your actual values

# ============================================================================
# Application Configuration
# ============================================================================
APP_NAME="QCM Generator Pro"
APP_VERSION="0.1.0"
DEBUG=false
LOG_LEVEL=INFO

# Environment: development, testing, production
ENVIRONMENT=development

# ============================================================================
# Server Configuration  
# ============================================================================
HOST=127.0.0.1
PORT=8000
RELOAD=true

# ============================================================================
# Database Configuration
# ============================================================================
DATABASE_URL=sqlite:///./data/database/qcm_generator.db

# For PostgreSQL (optional):
# DATABASE_URL=postgresql://user:password@localhost:5432/qcm_generator

# ============================================================================
# Database Configuration
# ============================================================================
DATABASE_URL=sqlite:///./data/database/qcm_generator.db

# ============================================================================
# LLM Configuration (prefix: LLM_)
# ============================================================================

# Default model configuration
LLM_DEFAULT_MODEL=gpt-4o-mini
LLM_MODEL_TYPE=openai

# OpenAI Configuration  
LLM_OPENAI_API_KEY=
LLM_OPENAI_MODEL=gpt-4o-mini
LLM_OPENAI_TIMEOUT=120

# Anthropic Configuration (optional)
LLM_ANTHROPIC_API_KEY=
LLM_ANTHROPIC_MODEL=claude-3-haiku-20240307
LLM_ANTHROPIC_TIMEOUT=120

# Ollama Configuration (for local models)
LLM_OLLAMA_BASE_URL=http://localhost:11434
LLM_OLLAMA_TIMEOUT=120

# Generation Parameters
LLM_DEFAULT_TEMPERATURE=0.7
LLM_DEFAULT_MAX_TOKENS=512
LLM_DEFAULT_TOP_P=0.9

# ============================================================================
# Processing Configuration (prefix: PROCESSING_)
# ============================================================================
PROCESSING_CHUNK_SIZE=2000
PROCESSING_CHUNK_OVERLAP=200
PROCESSING_MAX_PDF_SIZE_MB=50

# ============================================================================
# LangSmith Configuration (Optional - for LLM monitoring)
# ============================================================================
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=qcm-generator-pro
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# ============================================================================
# Server Configuration (for multi-service deployment)
# ============================================================================
API_HOST=0.0.0.0
API_PORT=8001
UI_HOST=0.0.0.0
UI_PORT=8501

# ============================================================================
# Docker Environment Variables (optional)
# ============================================================================
PYTHONPATH=/app
PYTHONDONTWRITEBYTECODE=1
PYTHONUNBUFFERED=1
