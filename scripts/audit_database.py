#!/usr/bin/env python3
"""
Script d'audit de la base de donnÃ©es SQLite pour comprendre l'Ã©tat actuel
"""

import sys
from pathlib import Path
import sqlite3
import json
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))


def audit_database():
    """Audit the current SQLite database."""
    print("ğŸ” Audit de la Base de DonnÃ©es SQLite")
    print("=" * 60)
    
    db_path = project_root / "data" / "database" / "qcm_generator.db"
    
    if not db_path.exists():
        print("âŒ Base de donnÃ©es non trouvÃ©e")
        return
    
    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        # List all tables
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = cursor.fetchall()
        
        print(f"ğŸ“š Tables trouvÃ©es: {len(tables)}")
        
        for table_name in tables:
            table = table_name[0]
            print(f"\nğŸ“‹ Table: {table}")
            print("-" * 40)
            
            # Get table info
            cursor.execute(f"PRAGMA table_info({table});")
            columns = cursor.fetchall()
            
            print("   Colonnes:")
            for col in columns:
                print(f"      - {col[1]} ({col[2]})")
            
            # Count records
            cursor.execute(f"SELECT COUNT(*) FROM {table};")
            count = cursor.fetchone()[0]
            print(f"   ğŸ“Š Nombre d'enregistrements: {count}")
            
            # Show sample data if exists
            if count > 0:
                cursor.execute(f"SELECT * FROM {table} LIMIT 3;")
                samples = cursor.fetchall()
                
                print("   ğŸ“„ Ã‰chantillons:")
                for i, sample in enumerate(samples, 1):
                    print(f"      Sample {i}: {sample}")
        
        # Specific analysis for documents
        print(f"\n{'='*60}")
        print("ğŸ“„ ANALYSE DES DOCUMENTS")
        print("=" * 60)
        
        try:
            cursor.execute("""
                SELECT id, filename, processing_status, total_pages, language, upload_date 
                FROM documents 
                ORDER BY upload_date DESC;
            """)
            documents = cursor.fetchall()
            
            if documents:
                print(f"âœ… {len(documents)} document(s) trouvÃ©(s):")
                for doc in documents:
                    doc_id, filename, status, pages, lang, upload_date = doc
                    print(f"   ğŸ“„ [{doc_id}] {filename}")
                    print(f"      Status: {status}, Pages: {pages}, Lang: {lang}")
                    print(f"      Upload: {upload_date}")
                    print()
            else:
                print("âŒ Aucun document trouvÃ© en base")
        except Exception as e:
            print(f"âš ï¸  Table documents non accessible: {e}")
        
        # Specific analysis for themes
        print("ğŸ¯ ANALYSE DES THÃˆMES")
        print("=" * 40)
        
        try:
            cursor.execute("""
                SELECT dt.id, dt.document_id, dt.theme_name, dt.confidence_score, d.filename
                FROM document_themes dt
                JOIN documents d ON dt.document_id = d.id
                ORDER BY dt.confidence_score DESC;
            """)
            themes = cursor.fetchall()
            
            if themes:
                print(f"âœ… {len(themes)} thÃ¨me(s) trouvÃ©(s):")
                for theme in themes:
                    theme_id, doc_id, name, confidence, filename = theme
                    print(f"   ğŸ¯ {name} (confidence: {confidence:.2f})")
                    print(f"      Document: {filename} [ID: {doc_id}]")
                    print()
            else:
                print("âŒ Aucun thÃ¨me trouvÃ© en base")
        except Exception as e:
            print(f"âš ï¸  Table themes non accessible: {e}")
        
        # Specific analysis for chunks
        print("ğŸ“ ANALYSE DES CHUNKS")
        print("=" * 40)
        
        try:
            cursor.execute("""
                SELECT dc.id, dc.document_id, dc.chunk_index, dc.content_preview, d.filename
                FROM document_chunks dc
                JOIN documents d ON dc.document_id = d.id
                ORDER BY dc.document_id, dc.chunk_index
                LIMIT 10;
            """)
            chunks = cursor.fetchall()
            
            if chunks:
                print(f"âœ… Chunks trouvÃ©s (10 premiers):")
                for chunk in chunks:
                    chunk_id, doc_id, index, preview, filename = chunk
                    preview_text = preview[:100] + "..." if preview and len(preview) > 100 else preview
                    print(f"   ğŸ“ Chunk {index} from {filename}")
                    print(f"      Preview: {preview_text}")
                    print()
            else:
                print("âŒ Aucun chunk trouvÃ© en base")
        except Exception as e:
            print(f"âš ï¸  Table chunks non accessible: {e}")
        
        conn.close()
        
    except Exception as e:
        print(f"âŒ Erreur lors de l'audit: {e}")


def check_current_workflow():
    """Check how the current application uses the database."""
    print(f"\n{'='*60}")
    print("ğŸ”§ ANALYSE DU WORKFLOW ACTUEL")
    print("=" * 60)
    
    try:
        # Check if services use the database
        from src.services.pdf_processor import process_pdf
        from src.services.rag_engine import get_rag_engine
        
        print("âœ… Services importÃ©s avec succÃ¨s")
        
        # Check RAG engine type
        rag_engine = get_rag_engine()
        rag_type = type(rag_engine).__name__
        print(f"ğŸ“Š Type de RAG Engine: {rag_type}")
        
        if hasattr(rag_engine, 'document_chunks'):
            chunks_count = len(rag_engine.document_chunks)
            print(f"ğŸ“ Chunks en mÃ©moire: {chunks_count}")
        
        # Check if database connection works
        try:
            from src.core.config import settings
            print(f"ğŸ”§ DB URL configurÃ©e: {settings.database.url}")
        except Exception as e:
            print(f"âš ï¸  Configuration DB: {e}")
            
    except Exception as e:
        print(f"âŒ Erreur analyse workflow: {e}")


def generate_migration_plan():
    """Generate a migration plan based on current state."""
    print(f"\n{'='*60}")
    print("ğŸ“‹ PLAN DE MIGRATION RECOMMANDÃ‰")
    print("=" * 60)
    
    print("""
ğŸ¯ OBJECTIFS:
   1. Rendre les documents et thÃ¨mes persistants et rÃ©utilisables
   2. IntÃ©grer ChromaDB pour la persistance des chunks RAG
   3. CrÃ©er une interface de gestion des documents existants

ğŸ“‹ PHASES RECOMMANDÃ‰ES:

Phase 1: PERSISTANCE RAG (PRIORITÃ‰ HAUTE)
   â”œâ”€â”€ Migrer SimpleRAGEngine vers ChromaDBRAGEngine
   â”œâ”€â”€ Sauvegarder les chunks dans ChromaDB lors du traitement
   â”œâ”€â”€ Charger les chunks depuis ChromaDB au dÃ©marrage
   â””â”€â”€ Tester la cohÃ©rence donnÃ©es SQLite â†” ChromaDB

Phase 2: INTERFACE DOCUMENTS EXISTANTS (PRIORITÃ‰ MOYENNE)
   â”œâ”€â”€ Ajouter onglet "Documents Existants" dans l'UI
   â”œâ”€â”€ Lister les documents traitÃ©s avec leurs thÃ¨mes
   â”œâ”€â”€ Permettre sÃ©lection/dÃ©sÃ©lection pour gÃ©nÃ©ration
   â””â”€â”€ Bouton de suppression des documents

Phase 3: RÃ‰UTILISATION THÃˆMES (PRIORITÃ‰ MOYENNE)
   â”œâ”€â”€ Interface de sÃ©lection des thÃ¨mes existants
   â”œâ”€â”€ Combinaison thÃ¨mes de plusieurs documents
   â”œâ”€â”€ Sauvegarde des prÃ©fÃ©rences de thÃ¨mes
   â””â”€â”€ Export/Import des configurations de thÃ¨mes

Phase 4: OPTIMISATIONS (PRIORITÃ‰ BASSE)
   â”œâ”€â”€ Cache intelligent des embeddings
   â”œâ”€â”€ DÃ©duplication des documents identiques
   â”œâ”€â”€ Compression/archivage des anciens documents
   â””â”€â”€ Statistiques d'utilisation

ğŸ’¡ POINTS D'ATTENTION:
   - Backup de la DB avant migration
   - Tests avec documents existants
   - Interface progressive (ne pas tout casser)
   - Performance avec beaucoup de documents
""")


if __name__ == "__main__":
    audit_database()
    check_current_workflow()
    generate_migration_plan()