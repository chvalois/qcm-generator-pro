# üéØ QCM Generator Pro - Local Edition

> **Application locale de g√©n√©ration automatique de QCM multilingues √† partir de documents PDF**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## üìã Table des Mati√®res

- [üéØ Aper√ßu](#-aper√ßu)
- [‚ú® Fonctionnalit√©s](#-fonctionnalit√©s)
- [üèóÔ∏è Architecture](#Ô∏è-architecture)
- [üöÄ Installation](#-installation)
- [üíª Utilisation](#-utilisation)
- [üê≥ Docker](#-docker)
- [üß™ Tests](#-tests)
- [üìä API Documentation](#-api-documentation)
- [üîß Configuration](#-configuration)
- [ü§ù Contribution](#-contribution)

## üéØ Aper√ßu

QCM Generator Pro est une application compl√®te de g√©n√©ration automatique de questions √† choix multiples (QCM) √† partir de documents PDF. Optimis√©e pour une utilisation locale avec support GPU (RTX 4090) et int√©gration d'APIs cloud.

### üé• D√©mo Rapide

```bash
# Installation rapide
git clone https://github.com/votre-username/qcm-generator-pro.git
cd qcm-generator-pro
make install-dev

# Lancement de l'interface web
make run-ui
```

![QCM Generator Interface](docs/images/interface-preview.png)

## ‚ú® Fonctionnalit√©s

### üéØ **G√©n√©ration Intelligente**
- ‚úÖ **Workflow progressif** (1 ‚Üí 5 ‚Üí toutes les questions)
- ‚úÖ **Validation automatique** avec points de contr√¥le utilisateur
- ‚úÖ **Multi-langues** (Fran√ßais, Anglais + extensible)
- ‚úÖ **Types de questions** : Choix unique, Choix multiples
- ‚úÖ **Niveaux de difficult√©** configurables (Facile, Moyen, Difficile)

### üìö **Gestion Documents**
- ‚úÖ **Upload PDF** avec validation et m√©tadonn√©es
- ‚úÖ **Extraction automatique de th√®mes** via LLM
- ‚úÖ **Persistance compl√®te** (SQLite + ChromaDB)
- ‚úÖ **Gestion avanc√©e** : suppression, statistiques, visualisations
- ‚úÖ **RAG Engine** pour g√©n√©ration contextuelle

### ü§ñ **Int√©gration LLM**
- ‚úÖ **Support multi-providers** : OpenAI, Anthropic, Ollama
- ‚úÖ **Mod√®les locaux** optimis√©s RTX 4090 (Mistral, Llama3, Phi-3)
- ‚úÖ **Fallback automatique** et gestion d'erreurs
- ‚úÖ **Test de connectivit√©** int√©gr√©

### üì§ **Export & Int√©gration**
- ‚úÖ **Format Udemy CSV** (compatible plateformes e-learning)
- ‚úÖ **Export JSON** avec m√©tadonn√©es compl√®tes
- ‚úÖ **Aper√ßu des questions** avant export
- ‚úÖ **Gestion des t√©l√©chargements**

### üé® **Interface Utilisateur**
- ‚úÖ **Interface web Streamlit** moderne et responsive
- ‚úÖ **Navigation √† onglets** : Upload, Gestion, G√©n√©ration, Export, Syst√®me
- ‚úÖ **Op√©rations en lot** pour la gestion de documents
- ‚úÖ **Visualisations interactives** (Plotly) des statistiques
- ‚úÖ **Mode debug** et monitoring syst√®me

## üèóÔ∏è Architecture

### üéØ **NOUVELLE ARCHITECTURE** *(Janvier 2025)*

L'architecture a √©t√© **compl√®tement r√©organis√©e** en domaines m√©tier pour une meilleure maintenabilit√© :

```mermaid
graph TB
    subgraph "üé® Interface Layer"
        UI[Streamlit Web UI]
        API[FastAPI REST API]
    end
    
    subgraph "üìÑ Document Domain"
        PDF[PDF Processor]
        THEME[Theme Extractor]
        TITLE[Title Detector]
        DOC[Document Manager]
    end
    
    subgraph "‚ö° Generation Domain"
        QCM[QCM Generator]
        CHUNK[Chunk Generator]
        TITLE_GEN[Title Generator]
        ENHANCED[Enhanced Generator]
        WORKFLOW[Progressive Workflow]
        PROMPT[Prompt Builder]
        PARSER[Question Parser]
        SELECT[Question Selection]
    end
    
    subgraph "‚úÖ Quality Domain"
        VAL[Validator]
        DEDUP[Deduplicator]
        DIVERSITY[Diversity Enhancer]
        VARIETY[Variety Validator]
    end
    
    subgraph "ü§ñ LLM Domain"
        LLM[LLM Manager]
        TRACK[LangSmith Tracker]
        EXAMPLES[Examples Loader]
        OPENAI[OpenAI API]
        ANTHROPIC[Anthropic API]
        OLLAMA[Ollama Local]
    end
    
    subgraph "üîß Infrastructure Domain"
        RAG[RAG Engine]
        PROGRESS[Progress Tracker]
        CHROMA[ChromaDB]
    end
    
    subgraph "üíæ Data Layer"
        DB[(SQLite Database)]
        RAG[(ChromaDB Vector Store)]
        FILES[üìÅ File Storage]
    end
    
    UI --> API
    API --> PDF
    API --> THEME
    API --> QCM
    PDF --> DB
    THEME --> LLM
    QCM --> LLM
    QCM --> RAG
    LLM --> OPENAI
    LLM --> ANTHROPIC
    LLM --> OLLAMA
```

### üÜï **Changements R√©cents** *(Janvier 2025)*

#### ‚úÖ **R√©organisation Architecture Services**
- **21 services** r√©organis√©s en **5 domaines m√©tier** clairs
- **50+ imports** mis √† jour dans toute la codebase
- **21/21 tests** passent toujours ‚úÖ
- **Scripts** corrig√©s pour les nouveaux chemins d'imports

#### üèóÔ∏è **Nouvelle Structure Services**
```
src/services/
‚îú‚îÄ‚îÄ document/          üìÑ Gestion documents (4 services)
‚îú‚îÄ‚îÄ generation/        ‚ö° G√©n√©ration QCM (8 services)  
‚îú‚îÄ‚îÄ quality/          ‚úÖ Assurance qualit√© (4 services)
‚îú‚îÄ‚îÄ llm/             ü§ñ Int√©gration LLM (3 services)
‚îî‚îÄ‚îÄ infrastructure/   üîß Services infrastructure (2 services)
```

#### üîÑ **Migration des Imports**
- **Avant** : `from src.services.llm_manager import ...`
- **Apr√®s** : `from src.services.llm.llm_manager import ...`

### üìÅ Structure du Projet

```
qcm-generator-pro/
‚îú‚îÄ‚îÄ üìÑ Documents & Config
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ CLAUDE.md                 # Context pour Claude Code
‚îÇ   ‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ üê≥ Docker
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml        # GPU deployment
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.cpu.yml    # CPU deployment
‚îú‚îÄ‚îÄ üß™ Tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/                     # Tests unitaires
‚îÇ   ‚îú‚îÄ‚îÄ integration/              # Tests d'int√©gration
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/                 # Donn√©es de test
‚îú‚îÄ‚îÄ üìú Scripts
‚îÇ   ‚îú‚îÄ‚îÄ start_app.py             # D√©marrage multi-processus
‚îÇ   ‚îú‚îÄ‚îÄ docker_setup.py          # Configuration Docker
‚îÇ   ‚îî‚îÄ‚îÄ integration_test.py      # Tests d'int√©gration
‚îî‚îÄ‚îÄ üéØ Source Code
    ‚îú‚îÄ‚îÄ api/                      # FastAPI endpoints
    ‚îÇ   ‚îú‚îÄ‚îÄ main.py
    ‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py
    ‚îÇ   ‚îî‚îÄ‚îÄ routes/
    ‚îú‚îÄ‚îÄ core/                     # Configuration & constantes
    ‚îÇ   ‚îú‚îÄ‚îÄ config.py
    ‚îÇ   ‚îú‚îÄ‚îÄ constants.py
    ‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py
    ‚îú‚îÄ‚îÄ models/                   # Mod√®les de donn√©es
    ‚îÇ   ‚îú‚îÄ‚îÄ database.py           # SQLAlchemy models
    ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Pydantic schemas
    ‚îÇ   ‚îî‚îÄ‚îÄ enums.py              # √ânum√©rations
    ‚îú‚îÄ‚îÄ services/                 # Logique m√©tier
    ‚îÇ   ‚îú‚îÄ‚îÄ pdf_processor.py
    ‚îÇ   ‚îú‚îÄ‚îÄ theme_extractor.py
    ‚îÇ   ‚îú‚îÄ‚îÄ rag_engine.py
    ‚îÇ   ‚îú‚îÄ‚îÄ llm_manager.py
    ‚îÇ   ‚îú‚îÄ‚îÄ qcm_generator.py
    ‚îÇ   ‚îú‚îÄ‚îÄ validator.py
    ‚îÇ   ‚îî‚îÄ‚îÄ document_manager.py
    ‚îú‚îÄ‚îÄ prompts/                  # Templates multilingues
    ‚îÇ   ‚îú‚îÄ‚îÄ templates.py
    ‚îÇ   ‚îî‚îÄ‚îÄ languages/
    ‚îî‚îÄ‚îÄ ui/                       # Interface utilisateur
        ‚îî‚îÄ‚îÄ streamlit_app.py
```

## üöÄ Installation

### üìã Pr√©requis

- **Python 3.11+**
- **Git**
- **Docker** (optionnel, pour le d√©ploiement containeris√©)
- **GPU RTX 4090** (optionnel, pour les mod√®les locaux)

### ‚ö° Installation Rapide

```bash
# 1. Cloner le repository
git clone https://github.com/votre-username/qcm-generator-pro.git
cd qcm-generator-pro

# 2. Installation des d√©pendances
make install-dev

# 3. Configuration
cp .env.example .env
# √âditer .env avec vos cl√©s API (optionnel)

# 4. Initialisation de la base de donn√©es
make db-init

# 5. Lancement de l'interface
make run-ui
```

### üîß Installation Manuelle

```bash
# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les d√©pendances
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Installer les hooks pre-commit
pre-commit install

# Initialiser la base de donn√©es
python -c "from src.models.database import init_database; init_database()"
```

## üíª Utilisation

### üéØ Interface Web (Recommand√©)

```bash
# Lancer l'interface Streamlit
make run-ui
# ou
streamlit run main_app.py
```

Ouvrez http://localhost:8501 dans votre navigateur.

### üõ†Ô∏è **Commandes Make Essentielles**

```bash
# üöÄ Lancement Application
make run-app          # Lance l'app compl√®te (API + UI) - RECOMMAND√â
make run-app-debug    # Lance en mode debug
make run-ui           # Interface Streamlit uniquement
make run              # API FastAPI uniquement

# üß™ Tests & Validation  
make test-working     # Tests valid√©s (21 tests) - RECOMMAND√â
make quick-check      # Validation rapide (format + lint + tests core)
make full-check       # Validation compl√®te

# üîß D√©veloppement
make install-dev      # Installation compl√®te environnement dev
make format           # Formatage code (black + ruff)
make lint             # Linting (ruff + mypy)

# üê≥ Docker
make docker-run       # Docker avec GPU
make docker-run-cpu   # Docker CPU uniquement
make docker-clean     # Nettoyage Docker
```

### üöÄ Workflow Complet

1. **üìÑ Upload de Documents**
   - S√©lectionnez un fichier PDF
   - Cliquez sur "üöÄ Traiter le document"
   - Visualisez les th√®mes extraits automatiquement

2. **üìö Gestion Documents**
   - Consultez vos documents stock√©s
   - Visualisez les statistiques et th√®mes
   - Supprimez ou organisez vos documents

3. **üéØ G√©n√©ration QCM**
   - Configurez le nombre de questions (1-50)
   - Ajustez la r√©partition des difficult√©s
   - S√©lectionnez les th√®mes sp√©cifiques
   - Suivez le workflow progressif :
     - **Phase 1** : 1 question test ‚Üí validation
     - **Phase 2** : 5 questions ‚Üí r√©vision
     - **Phase 3** : Questions restantes ‚Üí finalisation

4. **üì§ Export**
   - Choisissez le format : CSV (Udemy) ou JSON
   - T√©l√©chargez vos questions format√©es

### ü§ñ API REST

```bash
# Lancer le serveur API
make run
# ou
uvicorn src.api.main:app --reload
```

Documentation API : http://localhost:8000/docs

#### Exemples d'utilisation API

```python
import requests

# Upload d'un document
files = {'file': open('document.pdf', 'rb')}
response = requests.post('http://localhost:8000/documents/upload', files=files)

# G√©n√©ration de questions
config = {
    "num_questions": 10,
    "language": "fr",
    "difficulty_distribution": {"easy": 0.3, "medium": 0.5, "hard": 0.2}
}
response = requests.post('http://localhost:8000/generation/generate', json=config)
```

## üê≥ Docker

### üöÄ D√©ploiement GPU (RTX 4090)

```bash
# Build et lancement avec support GPU
make docker-build
make docker-run

# Ou manuellement
docker-compose up --build
```

### üíª D√©ploiement CPU

```bash
# Lancement CPU uniquement
make docker-run-cpu

# Ou manuellement
docker-compose -f docker-compose.cpu.yml up --build
```

### üîß Configuration Docker

Le d√©ploiement Docker inclut :
- **Service QCM Generator** (FastAPI + Streamlit)
- **Ollama** pour les mod√®les LLM locaux
- **Redis** pour le cache (optionnel)
- **Volumes persistants** pour donn√©es et mod√®les

Services disponibles :
- **Interface Web** : http://localhost:8501
- **API** : http://localhost:8000
- **Ollama** : http://localhost:11434

## üß™ Tests

### üèÉ Ex√©cution des Tests

#### ‚úÖ **Tests avec Nouvelle Architecture** 
```bash
# Tests recommand√©s (21 tests valid√©s)
make test-working

# Tous les tests avec couverture
make test

# Tests de base uniquement  
make test-basic

# Tests rapides (format + lint + tests core)
make quick-check

# V√©rification compl√®te (format + lint + tous les tests)
make full-check
```

#### üìä **Couverture de Tests**
- **21/21 tests** passent avec la nouvelle architecture ‚úÖ
- Tests des mod√®les, sch√©mas et fonctionnalit√©s de base
- Validation de l'int√©grit√© apr√®s r√©organisation des services

### üìä Couverture de Code

```bash
# Rapport de couverture
make test-cov

# Rapport HTML
coverage html
open htmlcov/index.html
```

**Objectif de couverture** : >90% pour les services core

### üß™ Tests Manuels

```bash
# Test de l'interface compl√®te
python scripts/integration_test.py

# Test des connexions LLM
python -c "from src.services.llm_manager import test_llm_connection_sync; print(test_llm_connection_sync())"
```

## üìä API Documentation

### üîó Endpoints Principaux

#### üìÑ Documents
- `POST /documents/upload` - Upload et traitement PDF
- `GET /documents/` - Liste des documents stock√©s
- `DELETE /documents/{id}` - Suppression de document
- `GET /documents/{id}/themes` - Th√®mes d'un document

#### üéØ G√©n√©ration
- `POST /generation/generate` - G√©n√©ration de questions
- `POST /generation/progressive` - Workflow progressif
- `GET /generation/sessions/{id}` - √âtat d'une session

#### üì§ Export
- `POST /export/csv` - Export CSV (Udemy)
- `POST /export/json` - Export JSON avec m√©tadonn√©es

#### ‚öôÔ∏è Syst√®me
- `GET /health` - √âtat de sant√© de l'application
- `GET /system/llm-status` - √âtat des connexions LLM
- `GET /system/metrics` - M√©triques syst√®me

### üìù Sch√©mas de Donn√©es

```python
# Configuration de g√©n√©ration
{
  "num_questions": 10,
  "language": "fr",
  "difficulty_distribution": {
    "easy": 0.3,
    "medium": 0.5,
    "hard": 0.2
  },
  "question_types": {
    "multiple-choice": 0.7,
    "multiple-selection": 0.3
  },
  "themes_filter": ["Th√®me 1", "Th√®me 2"]
}

# Question g√©n√©r√©e
{
  "question_text": "Qu'est-ce que Python ?",
  "question_type": "multiple-choice",
  "difficulty": "medium",
  "options": [
    {"text": "Un serpent", "is_correct": false},
    {"text": "Un langage de programmation", "is_correct": true},
    {"text": "Un fruit", "is_correct": false}
  ],
  "explanation": "Python est un langage de programmation...",
  "language": "fr"
}
```

## üîß Configuration

### üåç Variables d'Environnement

```bash
# Application
APP_NAME="QCM Generator Pro"
DEBUG=false

# Base de donn√©es
DATABASE_URL="sqlite:///data/qcm_generator.db"

# APIs LLM (optionnel)
OPENAI_API_KEY="sk-..."
ANTHROPIC_API_KEY="sk-ant-..."

# Mod√®les locaux
LOCAL_MODELS_DIR="./models"
OLLAMA_BASE_URL="http://localhost:11434"

# Traitement
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_PDF_SIZE_MB=50
```

### ü§ñ Configuration LLM

#### Mod√®les Locaux (Ollama)

```bash
# Installation des mod√®les recommand√©s
ollama pull mistral:7b-instruct
ollama pull llama3:8b-instruct
ollama pull phi3:mini

# Configuration dans l'app
DEFAULT_LLM="mistral-local"
```

#### APIs Cloud

```bash
# OpenAI
OPENAI_API_KEY="sk-..."
OPENAI_MODEL="gpt-3.5-turbo"

# Anthropic
ANTHROPIC_API_KEY="sk-ant-..."
ANTHROPIC_MODEL="claude-3-haiku-20240307"
```

### ‚öôÔ∏è Configuration Avanc√©e

```python
# src/core/config.py
class Settings(BaseSettings):
    # G√©n√©ration
    DEFAULT_QUESTIONS_COUNT: int = 10
    MAX_QUESTIONS_COUNT: int = 50
    
    # RAG
    CHUNK_SIZE: int = 1000
    CHUNK_OVERLAP: int = 200
    
    # LLM
    LLM_TIMEOUT: int = 60
    MAX_RETRIES: int = 3
```

## üöÄ Commandes Make

```bash
# üì¶ Installation
make install-dev          # Installation compl√®te dev
make setup-models         # T√©l√©chargement mod√®les LLM

# üèÉ Ex√©cution
make run                  # Serveur FastAPI
make run-ui              # Interface Streamlit
make run-full            # API + UI simultan√©ment

# üß™ Tests & Qualit√©
make test                # Tous les tests
make test-unit           # Tests unitaires
make test-cov            # Tests avec couverture
make lint                # Linting (ruff + mypy)
make format              # Formatage code

# üíæ Base de donn√©es
make db-init             # Initialisation DB
make db-reset            # Reset complet DB
make db-migrate          # Migrations

# üê≥ Docker
make docker-build        # Build images
make docker-run          # Lancement GPU
make docker-run-cpu      # Lancement CPU
make docker-logs         # Logs containers
make docker-shell        # Shell container

# üßπ Maintenance
make clean               # Nettoyage fichiers temporaires
make deps-update         # Mise √† jour d√©pendances
```

## ü§ù Contribution

### üîÑ Workflow de Contribution

1. **Fork** le repository
2. **Cr√©er** une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. **Commit** vos changements (`git commit -m 'Add: nouvelle fonctionnalit√©'`)
4. **Push** vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. **Ouvrir** une Pull Request

### üìã Standards de Code

```bash
# Avant chaque commit
make lint          # V√©rification du code
make test          # Tests complets
make format        # Formatage automatique
```

**Pre-commit hooks** configur√©s pour :
- **Ruff** (linting Python)
- **Black** (formatage Python)
- **MyPy** (v√©rification types)
- **Tests automatiques**

### üèóÔ∏è Architecture des Contributions

- **Services** : Logique m√©tier dans `src/services/`
- **API** : Endpoints REST dans `src/api/routes/`
- **UI** : Interface Streamlit dans `src/ui/`
- **Tests** : Tests unitaires/int√©gration dans `tests/`

### üìù Documentation

- **Docstrings** : Format Google/NumPy
- **Type hints** : Obligatoires pour toutes les fonctions
- **CLAUDE.md** : Contexte pour d√©veloppement IA

## üìû Support & Contact

### üêõ Signaler un Bug

1. **V√©rifiez** les [issues existantes](https://github.com/votre-username/qcm-generator-pro/issues)
2. **Cr√©ez** une nouvelle issue avec :
   - Description d√©taill√©e du probl√®me
   - √âtapes pour reproduire
   - Environment (OS, Python version, etc.)
   - Logs d'erreur

### üí° Demande de Fonctionnalit√©

Ouvrez une **feature request** avec :
- Description de la fonctionnalit√© souhait√©e
- Cas d'usage et b√©n√©fices
- Mockups/exemples si possible

### üìö Documentation

- **Documentation API** : http://localhost:8000/docs
- **Guide d√©veloppeur** : `CLAUDE.md`
- **Architecture** : Diagrammes dans `docs/`

## üìÑ Licence

```
MIT License

Copyright (c) 2024 QCM Generator Pro

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

<div align="center">

**üéØ QCM Generator Pro** - G√©n√©ration intelligente de QCM avec IA

[‚≠ê Star ce projet](https://github.com/votre-username/qcm-generator-pro) | [üêõ Signaler un bug](https://github.com/votre-username/qcm-generator-pro/issues) | [üí° Demander une fonctionnalit√©](https://github.com/votre-username/qcm-generator-pro/issues/new)

</div>